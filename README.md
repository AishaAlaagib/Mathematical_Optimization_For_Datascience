# Mathematical_Optimization_For_Datascience
Labs from the course *Mathematical Optimization for data-science* (2019 version) taught at *Telecom Paristech* by Pr. [Alexandre Gramfort](http://alexandre.gramfort.net/) and [Robert Gower](https://perso.telecom-paristech.fr/rgower/) in the context of the Msc data-science, a Master delivered by Ecole Polytechnique as part of the NewUni groupment of universities.

This course addresses the following topics:

- Lab 1: [ISTA and FISTA algorithms](https://blogs.princeton.edu/imabandit/2013/04/11/orf523-ista-and-fista/) for linear and [logistic](https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc) regression. [Regularization](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a)  with Ridge (L2), and Lasso (L1)
- Lab 2 : Comparison of deterministic algorithms FISTA, [GD](https://en.wikipedia.org/wiki/Gradient_descent), AGD, [CG](https://www.cs.cmu.edu/~quake-papers/painless-conjugate-gradient.pdf), [L-BFGS](http://aria42.com/blog/2014/12/understanding-lbfgs) and stochastic algorithms : [SGD](https://gluon.mxnet.io/chapter06_optimization/gd-sgd-scratch.html), [SVRG](https://www.cs.ubc.ca/~rezababa/Reza_files/wcom.pdf), [SAGA](https://www.di.ens.fr/~fbach/Defazio_NIPS2014.pdf)
